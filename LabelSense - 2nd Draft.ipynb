{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "db7d04a23e504df39a6a8b0121a6b7f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "RadioButtonsModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "RadioButtonsModel",
            "_options_labels": [
              "English only",
              "English + French",
              "English + Spanish",
              "All (English, French, Spanish)"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "RadioButtonsView",
            "description": "Select OCR Languages:",
            "description_tooltip": null,
            "disabled": false,
            "index": 3,
            "layout": "IPY_MODEL_a6abe5bd7b844dbd9f50386e7d3236fe",
            "style": "IPY_MODEL_52f2521000b546c38a85bddf3562de99"
          }
        },
        "a6abe5bd7b844dbd9f50386e7d3236fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52f2521000b546c38a85bddf3562de99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDbo9jUa4Ht4",
        "outputId": "3c3d9c41-a2e3-4ab8-fe38-25bce5b4575f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "db7d04a23e504df39a6a8b0121a6b7f2",
            "a6abe5bd7b844dbd9f50386e7d3236fe",
            "52f2521000b546c38a85bddf3562de99"
          ]
        },
        "id": "OhSVy6og3m3k",
        "outputId": "a0a7cb0f-8170-4aa8-b8a5-13db6f872ef0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LabelSense AI Food Label Analyzer\n",
            "=================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "RadioButtons(description='Select OCR Languages:', index=3, options=(('English only', 'eng'), ('English + Frenc…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db7d04a23e504df39a6a8b0121a6b7f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload a food label image to analyze:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-03266663-d3b3-4049-84b3-f819a874935d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-03266663-d3b3-4049-84b3-f819a874935d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving e5df08be-1257-476c-8749-3f18691b4013.jpeg to e5df08be-1257-476c-8749-3f18691b4013.jpeg\n",
            "Analyzing food label image using languages: eng+fra+spa...\n",
            "\n",
            "===== LabelSense AI Detailed Analysis Results =====\n",
            "Languages used for OCR: eng+fra+spa\n",
            "\n",
            "📋 EXTRACTED TEXT:\n",
            "----------------\n",
            "INGREDIENTS: BREAD (ENRICHED WHEAT FLOUR [WHEAT\n",
            "FLOUR, MALTED BARLEY FLOUR, NIACIN, IRON, THIAMIN\n",
            "MONONITRATE, RIBOFLAVIN, FOLIC ACID], WATER, YEAST,\n",
            "2% ORLESS OF SOYBEANOIL, WHEAT GLUTEN, SALT, SUGAR,\n",
            "ACETIC ACID, LACTIC ACID, FUMARIC ACID, ASCORBIC ACID,\n",
            "ENZYMES, CALCIUM PROPIONATE [PRESERVATIVE]), SAUCE\n",
            "(WATER, TOMATO PASTE, SUGAR, SOYBEAN OIL, 2% OR\n",
            "LESS OF MODIFIED FOOD STARCH, GARLIC, SPICES, SALT,\n",
            "DISTILLED VINEGAR, ONION, CULTURED DEXTROSE,\n",
            "POTASSIUM CHLORIDE, GARLIC POWDER, PAPRIKA,\n",
            "NATURALHICKORY SMOKE FLAVOR), CHEESE MOZZARELLA\n",
            "PART SKIM (PASTEURIZED PART SKIM MILK, CHEESE\n",
            "CULTURES, SALT, ENZYMES), PEPPERONI MADE WITHPORK,\n",
            "CHICKEN AND BEEF (PORK, MECHANICALLY SEPARATED\n",
            "CHICKEN, BEEF, SALT, CONTAINS 2% OR LESS OF SPICES,\n",
            "DEXTROSE, PORK STOCK, LACTIC ACID STARTER CULTURE,\n",
            "OLEORESIN OF PAPRIKA, FLAVORING, SODIUM NITRITE,\n",
            "SODIUM ASCORBATE, PAPRIKA, PROCESSED WITH\n",
            "NATURAL SMOKE FLAVOR, BHA, BHT, CITRIC ACID TO HELP\n",
            "PROTECT FLAVOR), MARGARINE (SOYBEAN OIL, WATER,\n",
            "MONO & DIGLYCERIDES, 2% OR LESS OF SALT, NATURAL\n",
            "FLAVOR, VITAMIN A PALMITATE, VITAMIN D3).\n",
            "CONTAINS: WHEAT, MILK,\n",
            "CONTAINS A BIOENGINEERED FOOD INGREDIENT\n",
            "\n",
            "🥘 INGREDIENTS DETECTED:\n",
            "---------------------\n",
            "1. bread __paren_0__\n",
            "2. enriched wheat flour [wheat flour\n",
            "3. malted barley flour\n",
            "4. niacin\n",
            "5. iron\n",
            "6. thiamin mononitrate\n",
            "7. riboflavin\n",
            "8. folic acid]\n",
            "9. water\n",
            "10. yeast\n",
            "11. 2% orless of soybeanoil\n",
            "12. wheat gluten\n",
            "13. salt\n",
            "14. sugar\n",
            "15. acetic acid\n",
            "16. lactic acid\n",
            "17. fumaric acid\n",
            "18. ascorbic acid\n",
            "19. enzymes\n",
            "20. calcium propionate [preservative]\n",
            "21. tomato paste\n",
            "22. soybean oil\n",
            "23. 2% or less of modified food starch\n",
            "24. garlic\n",
            "25. spices\n",
            "26. distilled vinegar\n",
            "27. onion\n",
            "28. cultured dextrose\n",
            "29. potassium chloride\n",
            "30. garlic powder\n",
            "31. paprika\n",
            "32. naturalhickory smoke flavor\n",
            "33. pasteurized part skim milk\n",
            "34. cheese cultures\n",
            "35. pork\n",
            "36. mechanically separated chicken\n",
            "37. beef\n",
            "38. contains 2% or less of spices\n",
            "39. dextrose\n",
            "40. pork stock\n",
            "41. lactic acid starter culture\n",
            "42. oleoresin of paprika\n",
            "43. flavoring\n",
            "44. sodium nitrite\n",
            "45. sodium ascorbate\n",
            "46. processed with natural smoke flavor\n",
            "47. bha\n",
            "48. bht\n",
            "49. citric acid to help protect flavor\n",
            "50. mono & diglycerides\n",
            "51. 2% or less of salt\n",
            "52. natural flavor\n",
            "53. vitamin a palmitate\n",
            "54. vitamin d3\n",
            "55. sauce __paren_1__\n",
            "56. cheese mozzarella part skim __paren_2__\n",
            "57. pepperoni made withpork\n",
            "58. chicken and beef __paren_3__\n",
            "59. margarine __paren_4__\n",
            "\n",
            "🌱 DIETARY ANALYSIS:\n",
            "-----------------\n",
            "Vegan Status: ❌ Not suitable for vegans\n",
            "Non-Vegan Ingredients:\n",
            "- pasteurized part skim milk\n",
            "- cheese cultures\n",
            "- pork\n",
            "- mechanically separated chicken\n",
            "- beef\n",
            "- pork stock\n",
            "- cheese mozzarella part skim __paren_2__\n",
            "- pepperoni made withpork\n",
            "- chicken and beef __paren_3__\n",
            "\n",
            "Vegetarian Status: ❌ Not suitable for vegetarians\n",
            "Non-Vegetarian Ingredients:\n",
            "- pork\n",
            "- mechanically separated chicken\n",
            "- beef\n",
            "- pork stock\n",
            "- pepperoni made withpork\n",
            "- chicken and beef __paren_3__\n",
            "\n",
            "⚠️ ALLERGEN INFORMATION:\n",
            "----------------------\n",
            "Allergens Found: ⚠️ Yes\n",
            "Potential Allergens:\n",
            "- enriched wheat flour [wheat flour\n",
            "- 2% orless of soybeanoil\n",
            "- wheat gluten\n",
            "- soybean oil\n",
            "- pasteurized part skim milk\n",
            "\n",
            "🔍 ADDITIONAL INFORMATION:\n",
            "------------------------\n",
            "This analysis is based on automated OCR and should not replace reading the actual label.\n",
            "If you have allergies or dietary restrictions, please consult the original packaging.\n"
          ]
        }
      ],
      "source": [
        "# LabelSense: AI-Driven Food Label Analyzer\n",
        "# An NLP Class Project Implementation\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pytesseract\n",
        "import re\n",
        "import os\n",
        "import requests\n",
        "import json\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "import warnings\n",
        "import sys\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import files\n",
        "\n",
        "# Install tesseract in Colab environment\n",
        "if 'google.colab' in sys.modules:\n",
        "    import subprocess\n",
        "    subprocess.run([\"apt-get\", \"update\"], check=True)\n",
        "    subprocess.run([\"apt-get\", \"install\", \"-y\", \"tesseract-ocr\"], check=True)\n",
        "    subprocess.run([\"apt-get\", \"install\", \"-y\", \"tesseract-ocr-eng\", \"tesseract-ocr-fra\", \"tesseract-ocr-spa\"], check=True)\n",
        "    subprocess.run([\"pip\", \"install\", \"pytesseract\"], check=True)\n",
        "    # Set path for Colab\n",
        "    pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'\n",
        "else:\n",
        "    # Set path for local Windows environment\n",
        "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load spaCy model\n",
        "try:\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "except:\n",
        "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"], check=True)\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Constants\n",
        "ALLERGENS = [\n",
        "    'milk', 'dairy', 'eggs', 'egg', 'peanuts', 'peanut', 'tree nuts', 'almond', 'almonds', 'walnut', 'walnuts',\n",
        "    'cashew', 'cashews', 'hazelnut', 'hazelnuts', 'shellfish', 'fish', 'wheat', 'gluten', 'soy', 'soya',\n",
        "    'sesame', 'mustard', 'celery', 'lupin', 'sulphites', 'sulfites', 'molluscs', 'mollusks'\n",
        "]\n",
        "\n",
        "NON_VEGAN = [\n",
        "    'milk', 'dairy', 'cheese', 'eggs', 'egg', 'honey', 'meat', 'beef', 'pork', 'chicken', 'turkey', 'lamb',\n",
        "    'gelatin', 'gelatine', 'lard', 'tallow', 'whey', 'casein', 'lactose', 'rennet', 'shellac', 'carmine',\n",
        "    'isinglass', 'albumin', 'cochineal', 'fish', 'shellfish', 'beef fat', 'butter', 'buttermilk', 'yogurt',\n",
        "    'cream', 'mayonnaise', 'bacon', 'duck', 'goose'\n",
        "]\n",
        "\n",
        "NON_VEGETARIAN = [\n",
        "    'meat', 'beef', 'pork', 'chicken', 'turkey', 'lamb', 'gelatin', 'gelatine', 'lard', 'tallow', 'rennet',\n",
        "    'shellac', 'isinglass', 'carmine', 'cochineal', 'fish', 'shellfish', 'beef fat', 'bacon', 'duck', 'goose'\n",
        "]\n",
        "\n",
        "# Class to handle image preprocessing\n",
        "class ImagePreprocessor:\n",
        "    @staticmethod\n",
        "    def resize_image(image, width=800):\n",
        "        \"\"\"Resize image while maintaining aspect ratio\"\"\"\n",
        "        h, w = image.shape[:2]\n",
        "        ratio = width / w\n",
        "        dim = (width, int(h * ratio))\n",
        "        return cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    @staticmethod\n",
        "    def denoise_image(image):\n",
        "        \"\"\"Apply denoising to the image\"\"\"\n",
        "        return cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_thresholding(image):\n",
        "        \"\"\"Apply thresholding to prepare for OCR\"\"\"\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        return cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "    @staticmethod\n",
        "    def detect_orientation(image):\n",
        "        \"\"\"Detect and correct image orientation\"\"\"\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        # Use Tesseract OSD to detect orientation\n",
        "        osd = pytesseract.image_to_osd(gray)\n",
        "        angle = int(re.search(r'(?<=Rotate: )\\d+', osd).group())\n",
        "\n",
        "        if angle != 0:\n",
        "            (h, w) = image.shape[:2]\n",
        "            center = (w // 2, h // 2)\n",
        "            M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "            image = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC,\n",
        "                                   borderMode=cv2.BORDER_REPLICATE)\n",
        "        return image\n",
        "\n",
        "    @staticmethod\n",
        "    def enhance_contrast(image):\n",
        "        \"\"\"Enhance contrast using CLAHE\"\"\"\n",
        "        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "        cl = clahe.apply(l)\n",
        "        limg = cv2.merge((cl, a, b))\n",
        "        return cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess(image):\n",
        "        \"\"\"Apply full preprocessing pipeline\"\"\"\n",
        "        if image is None:\n",
        "            raise ValueError(\"Image not loaded properly\")\n",
        "\n",
        "        try:\n",
        "            # Apply preprocessing steps\n",
        "            image = ImagePreprocessor.resize_image(image)\n",
        "            image = ImagePreprocessor.denoise_image(image)\n",
        "            image = ImagePreprocessor.enhance_contrast(image)\n",
        "\n",
        "            # Try to detect and correct orientation\n",
        "            try:\n",
        "                image = ImagePreprocessor.detect_orientation(image)\n",
        "            except:\n",
        "                pass  # Skip if orientation detection fails\n",
        "\n",
        "            # Create a binary version for OCR\n",
        "            binary = ImagePreprocessor.apply_thresholding(image)\n",
        "\n",
        "            return image, binary\n",
        "        except Exception as e:\n",
        "            print(f\"Error in preprocessing: {str(e)}\")\n",
        "            return image, None\n",
        "\n",
        "# Class to handle OCR operations\n",
        "class OCREngine:\n",
        "    @staticmethod\n",
        "    def extract_text(image, languages=None):\n",
        "        \"\"\"Extract text from the image using Tesseract OCR\n",
        "\n",
        "        Args:\n",
        "            image: The image to process\n",
        "            languages: Language codes to use (e.g., 'eng', 'fra', 'spa', 'eng+fra+spa')\n",
        "        \"\"\"\n",
        "        if languages is None:\n",
        "            languages = 'eng+fra+spa'  # Default to all supported languages\n",
        "\n",
        "        try:\n",
        "            # Extract using PSM 4 (assume a single column of text) with multiple languages\n",
        "            config = f'--psm 4 -l {languages}'\n",
        "            text = pytesseract.image_to_string(image, config=config)\n",
        "\n",
        "            # If little text is found, try different PSM modes\n",
        "            if len(text) < 50:\n",
        "                # Try different PSM modes to get the best results\n",
        "                text_psm_6 = pytesseract.image_to_string(image, config=f'--psm 6 -l {languages}')\n",
        "                text_psm_11 = pytesseract.image_to_string(image, config=f'--psm 11 -l {languages}')\n",
        "                text_psm_3 = pytesseract.image_to_string(image, config=f'--psm 3 -l {languages}')\n",
        "\n",
        "                # Use the one with most text\n",
        "                candidates = [text, text_psm_3, text_psm_6, text_psm_11]\n",
        "                text = max(candidates, key=len)\n",
        "\n",
        "            # Clean up the extracted text\n",
        "            text = text.replace('\\n\\n', '\\n').strip()\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            print(f\"OCR error: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_ingredients_section(text):\n",
        "        \"\"\"Extract the ingredients section from the OCR text\"\"\"\n",
        "        # Various ways ingredients sections are labeled\n",
        "        patterns = [\n",
        "            r'(?i)ingredients\\s*:(.+?)(?:\\.|$|\\n\\n|\\*{3})',\n",
        "            r'(?i)ingredients\\s*list\\s*:(.+?)(?:\\.|$|\\n\\n|\\*{3})',\n",
        "            r'(?i)contains\\s*:(.+?)(?:\\.|$|\\n\\n|\\*{3})',\n",
        "            r'(?i)ingred(?:i|l)ents\\s*:(.+?)(?:\\.|$|\\n\\n|\\*{3})',\n",
        "            r'(?i)ingredients?[\\s\\.\\)](.+?)(?:\\.|$|\\n\\n|\\*{3})',\n",
        "            r'(?i)ingredients(.+?)(?=allerg[ye]|$|\\n\\n|\\*{3})'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, text, re.DOTALL)\n",
        "            if match:\n",
        "                ingredients_text = match.group(1).strip()\n",
        "                if len(ingredients_text) > 20:  # Only return if we got a substantial match\n",
        "                    return ingredients_text\n",
        "\n",
        "        # If the text is short, it might be just the ingredients section itself\n",
        "        if len(text) < 1000 and ',' in text:\n",
        "            return text\n",
        "\n",
        "        # If no specific ingredients section is found, check if the whole text contains common ingredients\n",
        "        words = text.lower().split()\n",
        "        ingredient_markers = ['sugar', 'salt', 'flour', 'milk', 'butter', 'egg', 'oil']\n",
        "        if any(marker in words for marker in ingredient_markers):\n",
        "            return text\n",
        "\n",
        "        return text\n",
        "\n",
        "# Class to analyze ingredients\n",
        "class IngredientAnalyzer:\n",
        "    def __init__(self):\n",
        "        # Initialize ingredient database with Open Food Facts data\n",
        "        # In a real implementation, you would load this data from a database\n",
        "        self.ingredient_database = {\n",
        "            # Common ingredients and their properties\n",
        "            # Format: 'ingredient': {'vegan': bool, 'vegetarian': bool, 'allergen': bool}\n",
        "        }\n",
        "\n",
        "        # Load pre-defined lists\n",
        "        self.allergens = set(ALLERGENS)\n",
        "        self.non_vegan = set(NON_VEGAN)\n",
        "        self.non_vegetarian = set(NON_VEGETARIAN)\n",
        "\n",
        "        # Add cake-specific ingredients to the lists\n",
        "        self.allergens.update(['wheat', 'soya', 'sulphur dioxide', 'sulphites', 'sulfites'])\n",
        "        self.non_vegan.update(['milk powder', 'skimmed milk powder', 'milk powder', 'belgian chocolate', 'cocoa butter'])\n",
        "\n",
        "    def parse_ingredients(self, ingredients_text):\n",
        "        \"\"\"Parse the ingredients text into a list of individual ingredients\"\"\"\n",
        "        if not ingredients_text:\n",
        "            return []\n",
        "\n",
        "        # Clean up formatting\n",
        "        text = re.sub(r'\\s+', ' ', ingredients_text)\n",
        "\n",
        "        # Try to split by common separators while preserving parenthetical content\n",
        "        # First, extract all text in parentheses and replace with placeholders\n",
        "        parenthesis_contents = []\n",
        "        def replace_parens(match):\n",
        "            parenthesis_contents.append(match.group(1))\n",
        "            return f\"__PAREN_{len(parenthesis_contents)-1}__\"\n",
        "\n",
        "        # Replace parentheses content with placeholders\n",
        "        processed_text = re.sub(r'\\(([^)]+)\\)', replace_parens, text)\n",
        "\n",
        "        # Split by commas and other separators\n",
        "        raw_ingredients = re.split(r',|\\*|•|;', processed_text)\n",
        "        ingredients = []\n",
        "\n",
        "        # Process each raw ingredient\n",
        "        for raw in raw_ingredients:\n",
        "            raw = raw.strip().lower()\n",
        "            if not raw:\n",
        "                continue\n",
        "\n",
        "            # Replace parenthesis placeholders with original content\n",
        "            while '__PAREN_' in raw:\n",
        "                match = re.search(r'__PAREN_(\\d+)__', raw)\n",
        "                if match:\n",
        "                    idx = int(match.group(1))\n",
        "                    if idx < len(parenthesis_contents):\n",
        "                        raw = raw.replace(f\"__PAREN_{idx}__\", f\"({parenthesis_contents[idx]})\")\n",
        "\n",
        "            ingredients.append(raw)\n",
        "\n",
        "            # Also add the parenthetical parts as separate ingredients\n",
        "            for paren_content in parenthesis_contents:\n",
        "                sub_ingredients = re.split(r',|\\*|•|;', paren_content)\n",
        "                for sub in sub_ingredients:\n",
        "                    sub = sub.strip().lower()\n",
        "                    if sub and len(sub) > 2 and sub not in ingredients:\n",
        "                        ingredients.append(sub)\n",
        "\n",
        "        return ingredients\n",
        "\n",
        "    def is_vegan(self, ingredients):\n",
        "        \"\"\"Check if the ingredient list is vegan\"\"\"\n",
        "        if not ingredients:\n",
        "            return {\"is_vegan\": False, \"non_vegan_ingredients\": [\"Unknown ingredients\"]}\n",
        "\n",
        "        non_vegan_ingredients = []\n",
        "\n",
        "        for ingredient in ingredients:\n",
        "            # Check against non-vegan items\n",
        "            for non_vegan_item in self.non_vegan:\n",
        "                if non_vegan_item in ingredient.lower():\n",
        "                    non_vegan_ingredients.append(ingredient)\n",
        "                    break\n",
        "\n",
        "        return {\n",
        "            \"is_vegan\": len(non_vegan_ingredients) == 0,\n",
        "            \"non_vegan_ingredients\": non_vegan_ingredients\n",
        "        }\n",
        "\n",
        "    def is_vegetarian(self, ingredients):\n",
        "        \"\"\"Check if the ingredient list is vegetarian\"\"\"\n",
        "        if not ingredients:\n",
        "            return {\"is_vegetarian\": False, \"non_vegetarian_ingredients\": [\"Unknown ingredients\"]}\n",
        "\n",
        "        non_vegetarian_ingredients = []\n",
        "\n",
        "        for ingredient in ingredients:\n",
        "            # Check against non-vegetarian items\n",
        "            for non_veg_item in self.non_vegetarian:\n",
        "                if non_veg_item in ingredient.lower():\n",
        "                    non_vegetarian_ingredients.append(ingredient)\n",
        "                    break\n",
        "\n",
        "        return {\n",
        "            \"is_vegetarian\": len(non_vegetarian_ingredients) == 0,\n",
        "            \"non_vegetarian_ingredients\": non_vegetarian_ingredients\n",
        "        }\n",
        "\n",
        "    def find_allergens(self, ingredients):\n",
        "        \"\"\"Identify potential allergens in the ingredient list\"\"\"\n",
        "        if not ingredients:\n",
        "            return {\"allergens_found\": False, \"allergens\": []}\n",
        "\n",
        "        allergens_found = []\n",
        "\n",
        "        for ingredient in ingredients:\n",
        "            # Check against allergens list\n",
        "            for allergen in self.allergens:\n",
        "                if allergen in ingredient.lower():\n",
        "                    allergens_found.append(ingredient)\n",
        "                    break\n",
        "\n",
        "        return {\n",
        "            \"allergens_found\": len(allergens_found) > 0,\n",
        "            \"allergens\": allergens_found\n",
        "        }\n",
        "\n",
        "    def explain_ingredient(self, ingredient):\n",
        "        \"\"\"Provide a simple explanation of an ingredient\"\"\"\n",
        "        # This would ideally use a database or API to look up ingredients\n",
        "        # For demonstration, we'll return a simple placeholder\n",
        "        return f\"Definition of {ingredient}: This is a placeholder explanation. In a real implementation, this would provide detailed information about the ingredient.\"\n",
        "\n",
        "# Class to handle the complete analysis process\n",
        "class LabelSense:\n",
        "    def __init__(self):\n",
        "        self.preprocessor = ImagePreprocessor()\n",
        "        self.ocr_engine = OCREngine()\n",
        "        self.analyzer = IngredientAnalyzer()\n",
        "\n",
        "    def analyze_label(self, image_path, languages=None):\n",
        "        \"\"\"Analyze a food label image\n",
        "\n",
        "        Args:\n",
        "            image_path: Path to the image or image data\n",
        "            languages: Language codes to use for OCR (e.g., 'eng', 'fra', 'spa', 'eng+fra+spa')\n",
        "        \"\"\"\n",
        "        # Load the image\n",
        "        try:\n",
        "            if isinstance(image_path, str):\n",
        "                image = cv2.imread(image_path)\n",
        "            else:\n",
        "                # Assume it's already a numpy array\n",
        "                image = image_path\n",
        "\n",
        "            if image is None:\n",
        "                return {\"error\": \"Could not load image\"}\n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"Error loading image: {str(e)}\"}\n",
        "\n",
        "        # Preprocess the image\n",
        "        try:\n",
        "            processed_image, binary_image = self.preprocessor.preprocess(image)\n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"Error preprocessing image: {str(e)}\"}\n",
        "\n",
        "        # Extract text using OCR\n",
        "        try:\n",
        "            if binary_image is not None:\n",
        "                text = self.ocr_engine.extract_text(binary_image, languages)\n",
        "            else:\n",
        "                text = self.ocr_engine.extract_text(processed_image, languages)\n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"OCR error: {str(e)}\"}\n",
        "\n",
        "        # Extract ingredients section\n",
        "        ingredients_text = self.ocr_engine.extract_ingredients_section(text)\n",
        "\n",
        "        # Parse ingredients\n",
        "        ingredients = self.analyzer.parse_ingredients(ingredients_text)\n",
        "\n",
        "        # Analyze ingredients\n",
        "        vegan_results = self.analyzer.is_vegan(ingredients)\n",
        "        vegetarian_results = self.analyzer.is_vegetarian(ingredients)\n",
        "        allergen_results = self.analyzer.find_allergens(ingredients)\n",
        "\n",
        "        # Compile results\n",
        "        results = {\n",
        "            \"ingredients_detected\": ingredients,\n",
        "            \"vegan_analysis\": vegan_results,\n",
        "            \"vegetarian_analysis\": vegetarian_results,\n",
        "            \"allergen_analysis\": allergen_results,\n",
        "            \"full_text\": text,\n",
        "            \"languages_used\": languages or \"eng+fra+spa\"\n",
        "        }\n",
        "\n",
        "        return results\n",
        "\n",
        "# Function to download a sample image for testing\n",
        "def download_sample_image():\n",
        "    \"\"\"Download a sample food label image for testing\"\"\"\n",
        "    # Updated URL to a more reliable source\n",
        "    url = \"https://raw.githubusercontent.com/open-mmlab/mmocr/main/demo/demo_text_ocr.jpg\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        with open(\"sample_label.jpg\", \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "        return \"sample_label.jpg\"\n",
        "    else:\n",
        "        print(\"Failed to download sample image\")\n",
        "        return None\n",
        "\n",
        "# Main function to demonstrate the LabelSense system\n",
        "def main():\n",
        "    # Initialize LabelSense\n",
        "    label_sense = LabelSense()\n",
        "\n",
        "    # Download a sample image\n",
        "    print(\"Downloading a sample food label image...\")\n",
        "    sample_image_path = download_sample_image()\n",
        "\n",
        "    if sample_image_path:\n",
        "        print(f\"Sample image downloaded as {sample_image_path}\")\n",
        "\n",
        "        # Analyze the label\n",
        "        print(\"Analyzing food label...\")\n",
        "        results = label_sense.analyze_label(sample_image_path)\n",
        "\n",
        "        # Display results\n",
        "        print(\"\\n===== LabelSense Analysis Results =====\")\n",
        "\n",
        "        if \"error\" in results:\n",
        "            print(f\"Error: {results['error']}\")\n",
        "        else:\n",
        "            print(\"\\nIngredients Detected:\")\n",
        "            for ingredient in results[\"ingredients_detected\"]:\n",
        "                print(f\"- {ingredient}\")\n",
        "\n",
        "            print(\"\\nVegan Analysis:\")\n",
        "            print(f\"Is Vegan: {results['vegan_analysis']['is_vegan']}\")\n",
        "            if not results['vegan_analysis']['is_vegan']:\n",
        "                print(\"Non-Vegan Ingredients:\")\n",
        "                for ingredient in results['vegan_analysis']['non_vegan_ingredients']:\n",
        "                    print(f\"- {ingredient}\")\n",
        "\n",
        "            print(\"\\nVegetarian Analysis:\")\n",
        "            print(f\"Is Vegetarian: {results['vegetarian_analysis']['is_vegetarian']}\")\n",
        "            if not results['vegetarian_analysis']['is_vegetarian']:\n",
        "                print(\"Non-Vegetarian Ingredients:\")\n",
        "                for ingredient in results['vegetarian_analysis']['non_vegetarian_ingredients']:\n",
        "                    print(f\"- {ingredient}\")\n",
        "\n",
        "            print(\"\\nAllergen Analysis:\")\n",
        "            print(f\"Allergens Found: {results['allergen_analysis']['allergens_found']}\")\n",
        "            if results['allergen_analysis']['allergens_found']:\n",
        "                print(\"Allergens:\")\n",
        "                for allergen in results['allergen_analysis']['allergens']:\n",
        "                    print(f\"- {allergen}\")\n",
        "    else:\n",
        "        print(\"Could not download sample image. Please provide your own image path.\")\n",
        "\n",
        "# Example of running the analysis on a local image\n",
        "def analyze_local_image(image_path):\n",
        "    # Initialize LabelSense\n",
        "    label_sense = LabelSense()\n",
        "\n",
        "    # Analyze the label\n",
        "    print(f\"Analyzing food label from {image_path}...\")\n",
        "    results = label_sense.analyze_label(image_path)\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\n===== LabelSense Analysis Results =====\")\n",
        "\n",
        "    if \"error\" in results:\n",
        "        print(f\"Error: {results['error']}\")\n",
        "    else:\n",
        "        print(\"\\nIngredients Detected:\")\n",
        "        for ingredient in results[\"ingredients_detected\"]:\n",
        "            print(f\"- {ingredient}\")\n",
        "\n",
        "        print(\"\\nVegan Analysis:\")\n",
        "        print(f\"Is Vegan: {results['vegan_analysis']['is_vegan']}\")\n",
        "        if not results['vegan_analysis']['is_vegan']:\n",
        "            print(\"Non-Vegan Ingredients:\")\n",
        "            for ingredient in results['vegan_analysis']['non_vegan_ingredients']:\n",
        "                print(f\"- {ingredient}\")\n",
        "\n",
        "        print(\"\\nVegetarian Analysis:\")\n",
        "        print(f\"Is Vegetarian: {results['vegetarian_analysis']['is_vegetarian']}\")\n",
        "        if not results['vegetarian_analysis']['is_vegetarian']:\n",
        "            print(\"Non-Vegetarian Ingredients:\")\n",
        "            for ingredient in results['vegetarian_analysis']['non_vegetarian_ingredients']:\n",
        "                print(f\"- {ingredient}\")\n",
        "\n",
        "        print(\"\\nAllergen Analysis:\")\n",
        "        print(f\"Allergens Found: {results['allergen_analysis']['allergens_found']}\")\n",
        "        if results['allergen_analysis']['allergens_found']:\n",
        "            print(\"Allergens:\")\n",
        "            for allergen in results['allergen_analysis']['allergens']:\n",
        "                print(f\"- {allergen}\")\n",
        "\n",
        "# Advanced functionality: Train a custom model for ingredient detection\n",
        "def train_ingredient_detection_model():\n",
        "    \"\"\"Train a custom model to detect ingredients from label images\"\"\"\n",
        "    # This is a placeholder for a real training function\n",
        "    # In an actual implementation, this would:\n",
        "    # 1. Load a dataset of food label images with annotated ingredient lists\n",
        "    # 2. Extract features using computer vision techniques\n",
        "    # 3. Train a neural network to identify ingredients\n",
        "\n",
        "    # Example neural network architecture (not functional without proper dataset)\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')  # Number of classes would depend on the task\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(\"Model architecture defined for ingredient detection.\")\n",
        "    print(\"Note: This is a placeholder. Actual training requires a dataset.\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Function to build an ingredient database from Open Food Facts\n",
        "def build_ingredient_database():\n",
        "    \"\"\"Build an ingredient database from Open Food Facts data\"\"\"\n",
        "    # In a real implementation, you would:\n",
        "    # 1. Download the Open Food Facts data dump\n",
        "    # 2. Extract ingredient information\n",
        "    # 3. Build a database of ingredients with properties\n",
        "\n",
        "    print(\"Building ingredient database from Open Food Facts...\")\n",
        "    print(\"Note: This is a placeholder. Actual database building requires downloading and processing the Open Food Facts dataset.\")\n",
        "\n",
        "    # Example of how you would process the data\n",
        "    database = {}\n",
        "\n",
        "    # Placeholder for a few sample entries\n",
        "    database['sugar'] = {'vegan': True, 'vegetarian': True, 'allergen': False}\n",
        "    database['milk'] = {'vegan': False, 'vegetarian': True, 'allergen': True}\n",
        "    database['beef'] = {'vegan': False, 'vegetarian': False, 'allergen': False}\n",
        "\n",
        "    print(f\"Created a sample database with {len(database)} entries.\")\n",
        "    return database\n",
        "\n",
        "def analyze_label_image(image_file):\n",
        "    \"\"\"Create a detailed analysis of the uploaded image\"\"\"\n",
        "    # Initialize LabelSense\n",
        "    label_sense = LabelSense()\n",
        "\n",
        "    print(\"Which languages should be used for OCR?\")\n",
        "    print(\"1. English only\")\n",
        "    print(\"2. English + French\")\n",
        "    print(\"3. English + Spanish\")\n",
        "    print(\"4. All (English, French, Spanish)\")\n",
        "\n",
        "    try:\n",
        "        choice = int(input(\"Enter choice (1-4, default is 4): \") or \"4\")\n",
        "    except:\n",
        "        choice = 4\n",
        "\n",
        "    # Map choice to language codes\n",
        "    lang_map = {\n",
        "        1: \"eng\",\n",
        "        2: \"eng+fra\",\n",
        "        3: \"eng+spa\",\n",
        "        4: \"eng+fra+spa\"\n",
        "    }\n",
        "    languages = lang_map.get(choice, \"eng+fra+spa\")\n",
        "\n",
        "    # Analyze the label\n",
        "    print(f\"Analyzing food label image in detail using languages: {languages}...\")\n",
        "    results = label_sense.analyze_label(image_file, languages)\n",
        "\n",
        "    # Display results with more detailed information\n",
        "    print(\"\\n===== LabelSense AI Detailed Analysis Results =====\")\n",
        "    print(f\"Languages used for OCR: {results.get('languages_used', 'eng+fra+spa')}\")\n",
        "\n",
        "    if \"error\" in results:\n",
        "        print(f\"Error: {results['error']}\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n📋 EXTRACTED TEXT:\")\n",
        "    print(\"----------------\")\n",
        "    print(results[\"full_text\"])\n",
        "\n",
        "    print(\"\\n🥘 INGREDIENTS DETECTED:\")\n",
        "    print(\"---------------------\")\n",
        "    if results[\"ingredients_detected\"]:\n",
        "        for i, ingredient in enumerate(results[\"ingredients_detected\"], 1):\n",
        "            print(f\"{i}. {ingredient}\")\n",
        "    else:\n",
        "        print(\"No specific ingredients could be detected with confidence.\")\n",
        "\n",
        "    print(\"\\n🌱 DIETARY ANALYSIS:\")\n",
        "    print(\"-----------------\")\n",
        "    print(f\"Vegan Status: {'✅ Suitable' if results['vegan_analysis']['is_vegan'] else '❌ Not suitable'} for vegans\")\n",
        "    if not results['vegan_analysis']['is_vegan'] and results['vegan_analysis']['non_vegan_ingredients']:\n",
        "        print(\"Non-Vegan Ingredients:\")\n",
        "        for ingredient in results['vegan_analysis']['non_vegan_ingredients']:\n",
        "            print(f\"- {ingredient}\")\n",
        "\n",
        "    print(f\"\\nVegetarian Status: {'✅ Suitable' if results['vegetarian_analysis']['is_vegetarian'] else '❌ Not suitable'} for vegetarians\")\n",
        "    if not results['vegetarian_analysis']['is_vegetarian'] and results['vegetarian_analysis']['non_vegetarian_ingredients']:\n",
        "        print(\"Non-Vegetarian Ingredients:\")\n",
        "        for ingredient in results['vegetarian_analysis']['non_vegetarian_ingredients']:\n",
        "            print(f\"- {ingredient}\")\n",
        "\n",
        "    print(\"\\n⚠️ ALLERGEN INFORMATION:\")\n",
        "    print(\"----------------------\")\n",
        "    print(f\"Allergens Found: {'⚠️ Yes' if results['allergen_analysis']['allergens_found'] else '✅ None detected'}\")\n",
        "    if results['allergen_analysis']['allergens_found']:\n",
        "        print(\"Potential Allergens:\")\n",
        "        for allergen in results['allergen_analysis']['allergens']:\n",
        "            print(f\"- {allergen}\")\n",
        "\n",
        "    print(\"\\n🔍 ADDITIONAL INFORMATION:\")\n",
        "    print(\"------------------------\")\n",
        "    print(\"This analysis is based on automated OCR and should not replace reading the actual label.\")\n",
        "    print(\"If you have allergies or dietary restrictions, please consult the original packaging.\")\n",
        "\n",
        "# Main execution block at the end\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"LabelSense AI Food Label Analyzer\")\n",
        "    print(\"=================================\")\n",
        "\n",
        "    if 'google.colab' in sys.modules:\n",
        "        # Import IPython for interactive widgets\n",
        "        from IPython.display import display\n",
        "        import ipywidgets as widgets\n",
        "\n",
        "        # Create language selection widget\n",
        "        language_select = widgets.RadioButtons(\n",
        "            options=[\n",
        "                ('English only', 'eng'),\n",
        "                ('English + French', 'eng+fra'),\n",
        "                ('English + Spanish', 'eng+spa'),\n",
        "                ('All (English, French, Spanish)', 'eng+fra+spa')\n",
        "            ],\n",
        "            value='eng+fra+spa',\n",
        "            description='Select OCR Languages:',\n",
        "            disabled=False\n",
        "        )\n",
        "\n",
        "        display(language_select)\n",
        "        print(\"Upload a food label image to analyze:\")\n",
        "\n",
        "        # Upload the image\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        if uploaded:\n",
        "            image_path = list(uploaded.keys())[0]\n",
        "            selected_languages = language_select.value\n",
        "\n",
        "            # Initialize LabelSense\n",
        "            label_sense = LabelSense()\n",
        "\n",
        "            # Analyze the label\n",
        "            print(f\"Analyzing food label image using languages: {selected_languages}...\")\n",
        "            results = label_sense.analyze_label(image_path, selected_languages)\n",
        "\n",
        "            # Display results with more detailed information\n",
        "            print(\"\\n===== LabelSense AI Detailed Analysis Results =====\")\n",
        "            print(f\"Languages used for OCR: {results.get('languages_used', 'eng+fra+spa')}\")\n",
        "\n",
        "            if \"error\" in results:\n",
        "                print(f\"Error: {results['error']}\")\n",
        "            else:\n",
        "                print(\"\\n📋 EXTRACTED TEXT:\")\n",
        "                print(\"----------------\")\n",
        "                print(results[\"full_text\"])\n",
        "\n",
        "                print(\"\\n🥘 INGREDIENTS DETECTED:\")\n",
        "                print(\"---------------------\")\n",
        "                if results[\"ingredients_detected\"]:\n",
        "                    for i, ingredient in enumerate(results[\"ingredients_detected\"], 1):\n",
        "                        print(f\"{i}. {ingredient}\")\n",
        "                else:\n",
        "                    print(\"No specific ingredients could be detected with confidence.\")\n",
        "\n",
        "                print(\"\\n🌱 DIETARY ANALYSIS:\")\n",
        "                print(\"-----------------\")\n",
        "                print(f\"Vegan Status: {'✅ Suitable' if results['vegan_analysis']['is_vegan'] else '❌ Not suitable'} for vegans\")\n",
        "                if not results['vegan_analysis']['is_vegan'] and results['vegan_analysis']['non_vegan_ingredients']:\n",
        "                    print(\"Non-Vegan Ingredients:\")\n",
        "                    for ingredient in results['vegan_analysis']['non_vegan_ingredients']:\n",
        "                        print(f\"- {ingredient}\")\n",
        "\n",
        "                print(f\"\\nVegetarian Status: {'✅ Suitable' if results['vegetarian_analysis']['is_vegetarian'] else '❌ Not suitable'} for vegetarians\")\n",
        "                if not results['vegetarian_analysis']['is_vegetarian'] and results['vegetarian_analysis']['non_vegetarian_ingredients']:\n",
        "                    print(\"Non-Vegetarian Ingredients:\")\n",
        "                    for ingredient in results['vegetarian_analysis']['non_vegetarian_ingredients']:\n",
        "                        print(f\"- {ingredient}\")\n",
        "\n",
        "                print(\"\\n⚠️ ALLERGEN INFORMATION:\")\n",
        "                print(\"----------------------\")\n",
        "                print(f\"Allergens Found: {'⚠️ Yes' if results['allergen_analysis']['allergens_found'] else '✅ None detected'}\")\n",
        "                if results['allergen_analysis']['allergens_found']:\n",
        "                    print(\"Potential Allergens:\")\n",
        "                    for allergen in results['allergen_analysis']['allergens']:\n",
        "                        print(f\"- {allergen}\")\n",
        "\n",
        "                print(\"\\n🔍 ADDITIONAL INFORMATION:\")\n",
        "                print(\"------------------------\")\n",
        "                print(\"This analysis is based on automated OCR and should not replace reading the actual label.\")\n",
        "                print(\"If you have allergies or dietary restrictions, please consult the original packaging.\")\n",
        "    else:\n",
        "        # Option 1: Run with sample image download\n",
        "        main()\n",
        "\n",
        "        # Option 2: Run with your own image (replace with your image path)\n",
        "        # my_image_path = \"path/to/your/food_label.jpg\"  # Change this to your image path\n",
        "        # analyze_local_image(my_image_path)"
      ]
    }
  ]
}